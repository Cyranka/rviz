income_data_frame$Count <- as.numeric(as.character(income_data_frame$Count))
income_data_frame$Bracket <- as.character(income_data_frame$Bracket)
return(income_data_frame)
}
fb_ad_age <- function(id_vector, name_vector, platform){
suppressMessages(library(readxl))
age <- read_excel("age_for_fb_ads.xlsx", sheet = 1)
age_vector <- NULL
for(i in 1:nrow(age)){
age_vector[i] <- fbad_reachestimate(targeting_spec = list(
age_min = unbox(age$age_1[i]),
age_max = unbox(age$age_2[i]),
geo_locations = list(countries = 'US'),
publisher_platforms = platform,
flexible_spec = list(
list(interests = data.frame(
id = id_vector,
name = name_vector
))
)
))$users
print(paste(age$age_1[i],"-",age$age_2," Retrieved", " for ", name_vector,sep = ""))
Sys.sleep(3)
}
age_data_frame <- as.data.frame(cbind(age$Category, age_vector))
colnames(age_data_frame) <- c("Age Category","Count")
age_data_frame$Count <- as.numeric(age_data_frame$Count)
return(age_data_frame)
}
fb_ad_state <- function(id_vector, name_vector, platform){
suppressMessages(library(readxl))
states <- read.csv("state_codes_for_fb_ads.csv")
states_vector <- NULL
for(i in 1:nrow(states)){
states_vector[i] <- fbad_reachestimate(targeting_spec = list(
geo_locations = list(regions =data.frame(key = as.character(states$key[i]))),
publisher_platforms = platform,
flexible_spec = list(list(
interests = data.frame(
id = as.character(id_vector),
name = as.character(name_vector)
)
))
))$users
print(paste(states$name[i], " Retrieved", " for ", name_vector,sep = ""))
}
state_data_frame <- as.data.frame(cbind(states$name,states_vector))
colnames(state_data_frame) <- c("State", "Count")
state_data_frame$Count <- as.numeric(state_data_frame$Count)
return(state_data_frame)
}
fb_ad_top_dmas <- function(id_vector, name_vector, the_platform){
suppressMessages(library(readxl))
states <- read_excel("dma_fb_list.xlsx", sheet = 1)
states <- states[c(1:50),]
states_vector <- NULL
for(i in 1:50){
states_vector[i] <- fbad_reachestimate(targeting_spec = list(
geo_locations = list(geo_markets = data.frame(key = states$key[i])),
publisher_platforms = the_platform,
flexible_spec = list(list(
interests = data.frame(
id = as.character(id_vector),
name = as.character(name_vector)
)
))
))$users
print(paste(states$name[i], " Retrieved", " for ", name_vector,sep = ""))
}
dma_data_frame <- as.data.frame(cbind(states$name,states_vector))
colnames(dma_data_frame) <- c("dma", "count")
dma_data_frame$count <- as.numeric(dma_data_frame$count)
dma_data_frame <- arrange(dma_data_frame, desc(count))
return(dma_data_frame)
}
fb_ad_gender <- function(id_vector, name_vector, platform){
gender_identifier <- c("Male", "Female")
gender_numbers <- c(1,2)
gender_vector <- NULL
for(i in 1:2){
gender_vector[i] <- fbad_reachestimate(targeting_spec = list(
genders = gender_numbers[i],
geo_locations = list(countries = 'US'),
publisher_platforms = platform,
flexible_spec = list(list(
interests = data.frame(
id = as.character(id_vector),
name = as.character(name_vector)
)
))
))$users
print(paste(gender_identifier[i], " Retrieved", " for ", name_vector,sep = ""))
}
my_data_frame <- as.data.frame(cbind(gender_identifier,as.numeric(as.character(gender_vector))))
colnames(my_data_frame) <- c("Gender", "Count")
return(my_data_frame)
}
fb_ad_ideology <- function(id_vector, name_vector, platform){
categories <- read_excel("categories_for_fb_ads.xlsx", sheet = 1)
political <- subset(categories, categories$type == "politics")
political_vector <- NULL
for(i in 1:nrow(political)){
political_vector[i] <- fbad_reachestimate(targeting_spec = list(
geo_locations = list(countries = 'US'),
publisher_platforms = platform,
flexible_spec = list(
list(interests = data.frame(
id = id_vector,
name = name_vector
)),
list(politics = data.frame(
id = political$id[i],
name = political$Name[i]
))
))
)$users
print(paste(as.character(political$Name)[i], " Retrieved", " for ", as.character(name_vector) ,sep = ""))
}
ideology_vector <- c("Very Liberal", "Liberal", "Moderate","Conservative", "Very Conservative",
"Conservative Activist", "Liberal Activist",
"Conservative Donor", "Liberal Donor")
my_data_frame <- as.data.frame(cbind(ideology_vector,as.numeric(as.character(political_vector))))
colnames(my_data_frame) <- c("Politics","Count")
return(my_data_frame)
}
fb_ad_race <- function(id_vector, name_vector, platform){
race_ids <- c("6021722613183","6018745176183","6003133212372")
race_names <- c("Asian American (US)","African American (US)","Hispanic (US - All)","White")
race_vector <- NULL
##get minorities##
for(i in 1:3){
race_vector[i] <- fbad_reachestimate(targeting_spec = list(
geo_locations = list(countries = 'US'),
publisher_platforms = platform,
flexible_spec = list(
list(interests = data.frame(
id = id_vector,
name = name_vector
)),
list(behaviors = data.frame(
id = race_ids[i],
name = race_names[i]
))
)
))$users
print(paste(race_names[i]," Retrieved", " for ", name_vector,sep = ""))
}
##get whites
race_vector[4] <- fbad_reachestimate(targeting_spec = list(
geo_locations = list(countries = 'US'),
publisher_platforms = platform,
flexible_spec = list(
list(interests = data.frame(
id = as.character(id_vector),
name = as.character(name_vector)
))),
exclusions  = list(behaviors = data.frame(
id = as.character(race_ids),
name =as.character(race_vector)
))
)
)$users
print(paste("Whites retrieved for ",name_vector, sep = ""))
race_data_frame <- as.data.frame(cbind(race_names, race_vector))
colnames(race_data_frame) <- c("Ethnic/Cultural Group","Count")
race_data_frame$Count <- as.numeric(race_data_frame$Count)
race_data_frame$percent <- race_data_frame$Count/sum(race_data_frame$Count)
race_data_frame <- race_data_frame[c(4,2,3,1),]
return(race_data_frame)
}
fb_ad_parents <- function(id_vector, name_vector, my_platform){
suppressMessages(library(readxl))
if(my_platform == "Combined"){
my_platform <- c("facebook","instagram")
}else{
my_platform = my_platform
}
categories <- read_excel("categories_for_fb_ads2.xlsx")
parents <- categories[1:8,]
parents <- categories[c(8,1,2,3,4,5,6,7),]
print(paste('Fetching parents data for ', name_vector))
parents_vector <- unlist(lapply(1:nrow(parents), function(i)fbad_reachestimate(targeting_spec = list(
geo_locations = list(countries = 'US'),
publisher_platforms = my_platform,
flexible_spec = list(
list(interests = data.frame(
id = id_vector,
name = name_vector
)),
list(family_statuses = data.frame(
id = parents$id[i],
name = parents$name[i]
))
)
))$users
))
parents_data_frame <- as.data.frame(cbind(parents$name, parents_vector))
colnames(parents_data_frame) <- c("Parents","Count")
parents_data_frame$Count <- as.numeric(parents_data_frame$Count)
return(parents_data_frame)
}
fb_get_all <- function(id_vector, name_vector, file_name, my_platform){
options(stringsAsFactors = FALSE)
options(scipen = 999)
incomes <- read_excel("income_distribution_fb_ads.xlsx", sheet = 1)
states <- read.csv("state_codes_for_fb_ads.csv")
age <- read_excel("age_for_fb_ads.xlsx", sheet = 1)
if(my_platform == "Combined"){
my_platform <- c("facebook","instagram")
}else{
my_platform = my_platform
}
z <- fb_ad_income(id_vector = id_vector, name_vector = name_vector, my_platform)
x <- fb_ad_age(id_vector = id_vector, name_vector = name_vector, my_platform)
v <- fb_ad_state(id_vector = id_vector, name_vector = name_vector, my_platform)
k <- fb_ad_race(id_vector = id_vector, name_vector = name_vector, my_platform)
l <- fb_ad_gender(id_vector = id_vector, name_vector = name_vector, my_platform)
a <- fb_ad_ideology(id_vector = id_vector, name_vector = name_vector, my_platform)
a_2 <- fb_ad_industries(id_vector = id_vector, name_vector = name_vector, my_platform)
a_3 <- fb_ad_education(id_vector = id_vector, name_vector = name_vector, my_platform)
write.xlsx(z, file = paste(file_name,".xlsx",sep = ""), sheetName = "income", append=FALSE, row.names = FALSE)
write.xlsx(x, file = paste(file_name,".xlsx",sep = ""), sheetName = "age", append=TRUE, row.names = FALSE)
write.xlsx(v, file = paste(file_name,".xlsx",sep = ""), sheetName = "state", append=TRUE, row.names = FALSE)
write.xlsx(k, file = paste(file_name,".xlsx",sep = ""), sheetName = "ethnicity", append=TRUE, row.names = FALSE)
write.xlsx(l, file = paste(file_name,".xlsx",sep = ""), sheetName = "gender", append=TRUE, row.names = FALSE)
write.xlsx(a, file = paste(file_name,".xlsx",sep = ""), sheetName = "ideology", append=TRUE, row.names = FALSE)
write.xlsx(a_2, file = paste(file_name,".xlsx",sep = ""), sheetName = "industries", append=TRUE, row.names = FALSE)
write.xlsx(a_3, file = paste(file_name,".xlsx",sep = ""), sheetName = "education", append=TRUE, row.names = FALSE)
my_list <- list(z,x,v,l,k,a,a_2,a_3)
return(my_list)
}
fb_ad_gender(NULL, NULL, "facebook")
fb_ad_income(NULL, NULL, "facebook")
remove(list = ls())
options(stringsAsFactors = FALSE)
options(scipen = 999)
EAAHmHiwelgUBAOZBPWHh3rVi9FNHhh0ernO59DB9kk7wAT8N0DigiWJhoL0A07mhpQgwR6wp8Q4BaaZAjQZBFoFmFhAdelZCJHNGGvnvRFveIz9sGzfJerpQL4ZCwOl05pu6VrOfiSu1MeWJGngV8O50tAXZCDRZAZAyCoOJOjM9nAZDZD"
token <- "EAAHmHiwelgUBAOZBPWHh3rVi9FNHhh0ernO59DB9kk7wAT8N0DigiWJhoL0A07mhpQgwR6wp8Q4BaaZAjQZBFoFmFhAdelZCJHNGGvnvRFveIz9sGzfJerpQL4ZCwOl05pu6VrOfiSu1MeWJGngV8O50tAXZCDRZAZAyCoOJOjM9nAZDZD"
accounts <- fbad_get_my_ad_accounts(token, version = '3.1')
library(fbRads)
token <- "EAAHmHiwelgUBAOZBPWHh3rVi9FNHhh0ernO59DB9kk7wAT8N0DigiWJhoL0A07mhpQgwR6wp8Q4BaaZAjQZBFoFmFhAdelZCJHNGGvnvRFveIz9sGzfJerpQL4ZCwOl05pu6VrOfiSu1MeWJGngV8O50tAXZCDRZAZAyCoOJOjM9nAZDZD"
accounts <- fbad_get_my_ad_accounts(token, version = '3.1')
accoutns
accounts
account <- sample(accounts$account_id, 1)
fbad_init(accountid = account, token = token, version = '3.1')
fb_ad_us_audience <- function(id_vector, name_vector, platform){
audience <- NULL
audience <- fbad_reachestimate(targeting_spec = list(
geo_locations = list(countries = 'US'),
publisher_platforms = platform,
flexible_spec = list(
list(interests = data.frame(
id = as.character(id_vector),
name = as.character(name_vector)
))
)
))$users
print(paste("US Audience", " Retrieved", " for ", name_vector,sep = ""))
return(audience)
}
fb_ad_us_audience(NULL, NULL, "facebook")
fbad_get_search(q = "Boston Celtics", type ="targetingsearch")[,1:3]
remove(list = ls())
options(stringsAsFactors = FALSE)
options(scipen = 999)
setwd("/Users/harrocyranka/Desktop/rviz/tidy_tuesday_week_20/")
library(tidyverse);library(tidytext)
csv_files <- grep("\\.csv",list.files(), value = TRUE)
x <- bind_rows(lapply(csv_files, function(i) read_csv(i)))
english <- x %>% filter(language == "English")
hashtags <- tibble(hashtag = stringr::str_extract_all(rtweet::plain_tweets(english$content),"#\\S+"))
hashtags
hashtags <- tibble(hashtag = unlist(stringr::str_extract_all(rtweet::plain_tweets(english$content),"#\\S+")))
hashtags
hashtags %>% mutate(hashtag = str_to_lower(hashtag))
totals <- hashtags %>% mutate(hashtag = str_to_lower(hashtag)) %>%
group_by(hashtag) %>% tally(sort = TRUE)
saveRDS(hashtags, "hashtags_politics.RDS")
hashtags <- readRDS("hashtags_politics.RDS")
hashtags
totals <- hashtags %>% mutate(hashtag = str_to_lower(hashtag)) %>%
group_by(hashtag) %>% tally(sort = TRUE)
totals
View(totals)
hashtags <- readRDS("hashtags_politics.RDS")
totals <- hashtags %>% mutate(hashtag = str_to_lower(hashtag)) %>%
group_by(hashtag) %>% tally(sort = TRUE) %>%
filter(n > 150)
View(totals)
saveRDS(hashtags, "all_hashtags.RDS")
hashtags <- readRDS("all_hashtags.RDS")
totals <- hashtags %>% mutate(hashtag = str_to_lower(hashtag)) %>%
group_by(hashtag) %>% tally(sort = TRUE) %>%
filter(n > 150)
colnames(x)
table(x$post_type)
table(x$account_category)
politics <- x %>% filter(language == "English") %>%
filter(account_category %in% c("RightTroll","LeftTroll"))
pol_hashtags <- tibble(hashtag = unlist(stringr::str_extract_all(rtweet::plain_tweets(politics$content),"#\\S+")))
saveRDS(pol_hashtags, "political_hashtags.RDS")
pol_hashtags <- readRDS("political_hashtags.RDS")
pol_hashtags
total_pols <- pol_hashtags %>% mutate(hashtag = str_to_lower(hashtag)) %>%
count(hashtag, sort = TRUE)
View(total_pols)
total_pols
total_pols <- pol_hashtags %>% mutate(hashtag = str_to_lower(hashtag)) %>%
count(hashtag, sort = TRUE) %>% filter(n > 100)
View(total_pols)
read_csv("/Users/harrocyranka/Desktop/Research_and_Projects/dead_projects/classified/twitter_targets/classified_targets_profiles.csv") %>%
filter(followersCount > 100) %>% nrow()
read_csv("/Users/harrocyranka/Desktop/Research_and_Projects/dead_projects/classified/twitter_targets/classified_targets_profiles.csv") %>% nrow()
read_csv("/Users/harrocyranka/Desktop/Research_and_Projects/dead_projects/classified/twitter_targets/classified_targets_profiles.csv") %>%
filter(followersCount > 1000) %>% nrow()
total_pols
View(x)
View(politics)
politics <- politics %>% filter(is.na(post_type))
politics <- politics %>% filter(is.na(post_type)) %>%
mutate(content = rtweet::plain_tweets(content))
View(politics)
politics <- politics %>% mutate(content = gsub("'$|^'","",content)) %>%
mutate(content = gsub('"$|^"',content))
politics <- politics %>% mutate(content = gsub("'$|^'","",content)) %>%
mutate(content = gsub('"$|^"',"",content))
politics <- politics %>% mutate(content = gsub("'$|^'","",content)) %>%
mutate(content = gsub('"$|^"',"",content)) %>%
mutate(date = lubridate::mdy(gsub("\\s.*","",date)))
gsub("\\s.*","",politics$date)
politics <- politics %>% mutate(content = gsub("'$|^'","",content)) %>%
mutate(content = gsub('"$|^"',"",content)) %>%
mutate(publish_date = lubridate::mdy(gsub("\\s.*","",publish_date)))
replace_reg <- "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https"
unnest_reg <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"
politics %>%
mutate(content = str_replace_all(content, replace_reg, "")) %>%
unnest_tokens(word, content, token = "regex", pattern = unnest_reg)
politics %>% select(content, publish_date, account_type) %>%
mutate(content = str_replace_all(content, replace_reg, "")) %>%
unnest_tokens(word, content, token = "regex", pattern = unnest_reg)
tidy_politics <- politics %>% select(content, publish_date, account_type) %>%
mutate(content = str_replace_all(content, replace_reg, "")) %>%
unnest_tokens(word, content, token = "regex", pattern = unnest_reg)
tidy_politics <- politics %>% select(content, publish_date, account_type) %>%
mutate(content = str_replace_all(content, replace_reg, "")) %>%
unnest_tokens(word, content, token = "regex", pattern = unnest_reg) %>%
anti_join(stop_words$word)
tidy_politics <- politics %>% select(content, publish_date, account_type) %>%
mutate(content = str_replace_all(content, replace_reg, "")) %>%
unnest_tokens(word, content, token = "regex", pattern = unnest_reg) %>%
anti_join(stop_words)
tidy_politics
tidy_politics %>% group_by(account_type, word) %>% tally()
tidy_politics %>% group_by(account_type, word) %>% tally() %>%
filter(n > 30)
tidy_politics %>% group_by(account_type, word) %>% tally() %>%
filter(n > 100)
tidy_politics %>% group_by(account_type, word) %>% tally() %>%
filter(n > 100) %>%
left_join(tidy_politics %>% count(account_type))
tidy_politics %>% count(account_type, sort = TRUE)
tidy_politics %>% mutate(account_type = ifelse(account_type == "right", "Right", account_type)) %>%
group_by(account_type, word) %>% tally() %>%
filter(n > 100) %>%
left_join(tidy_politics %>%mutate(account_type = ifelse(account_type == "right", "Right", account_type) %>%
%>% count(account_type, sort = TRUE) %>% rename(total = n)))
tidy_politics %>% mutate(account_type = ifelse(account_type == "right", "Right", account_type)) %>%
group_by(account_type, word) %>% tally() %>%
filter(n > 100) %>%
left_join(tidy_politics %>%mutate(account_type = ifelse(account_type == "right", "Right", account_type)) %>%
%>% count(account_type, sort = TRUE) %>% rename(total = n)))
tidy_politics %>% mutate(account_type = ifelse(account_type == "right", "Right", account_type)) %>%
group_by(account_type, word) %>% tally() %>%
filter(n > 100) %>%
left_join(tidy_politics %>%mutate(account_type = ifelse(account_type == "right", "Right", account_type)) %>%
count(account_type, sort = TRUE) %>% rename(total = n)))
tidy_politics %>% mutate(account_type = ifelse(account_type == "right", "Right", account_type)) %>%
group_by(account_type, word) %>% tally() %>%
filter(n > 100) %>%
left_join(tidy_politics %>%
mutate(account_type = ifelse(account_type == "right", "Right", account_type)) %>%
count(account_type, sort = TRUE) %>% rename(total = n))
for_graph <- tidy_politics %>% mutate(account_type = ifelse(account_type == "right", "Right", account_type)) %>%
group_by(account_type, word) %>% tally() %>%
filter(n > 100) %>%
left_join(tidy_politics %>%
mutate(account_type = ifelse(account_type == "right", "Right", account_type)) %>%
count(account_type, sort = TRUE) %>% rename(total = n)) %>%
mutate(proportion = n/total)
View(for_graph)
for_graph
for_graph %>% ungroup()
for_graph %>% ungroup() %>%
select(-n:total)
for_graph %>% ungroup() %>%
select(-n, -total)
for_graph %>% ungroup() %>%
select(-n, -total) %>%
spread(account_type, proportion)
for_graph %>% ungroup() %>%
select(-n, -total)
for_graph %>% ungroup() %>%
select(-n, -total) %>%
spread(account_type, proportion, fill = 0) %>%
ggplot(aes(left, Right)) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
geom_abline(color = "red")
library(scales)
for_graph %>% ungroup() %>%
select(-n, -total) %>%
spread(account_type, proportion, fill = 0) %>%
ggplot(aes(left, Right)) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
geom_abline(color = "red")
library(scales)
for_graph %>% ungroup() %>%
select(-n, -total) %>%
spread(account_type, proportion) %>%
ggplot(aes(left, Right)) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
geom_abline(color = "red")
my_words <- readxl::read_excel("most_common_words_english_for_twitter.xlsx")
my_words
##
my_words <- readxl::read_excel("most_common_words_english_for_twitter.xlsx")
replace_reg <- "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https"
unnest_reg <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"
tidy_politics <- politics %>% select(content, publish_date, account_type) %>%
mutate(content = str_replace_all(content, replace_reg, "")) %>%
unnest_tokens(word, content, token = "regex", pattern = unnest_reg) %>%
anti_join(stop_words) %>% anti_join(my_words)
##
for_graph <- tidy_politics %>% mutate(account_type = ifelse(account_type == "right", "Right", account_type)) %>%
group_by(account_type, word) %>% tally() %>%
filter(n > 100) %>%
left_join(tidy_politics %>%
mutate(account_type = ifelse(account_type == "right", "Right", account_type)) %>%
count(account_type, sort = TRUE) %>% rename(total = n)) %>%
mutate(proportion = n/total)
library(scales)
for_graph %>% ungroup() %>%
select(-n, -total) %>%
spread(account_type, proportion) %>%
ggplot(aes(left, Right)) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
geom_abline(color = "red")
tidy_politics <- politics %>% select(content, publish_date, account_type) %>%
mutate(content = tm::removeNumbers(str_replace_all(content, replace_reg, ""))) %>%
unnest_tokens(word, content, token = "regex", pattern = unnest_reg) %>%
anti_join(stop_words) %>% anti_join(my_words)
##
for_graph <- tidy_politics %>% mutate(account_type = ifelse(account_type == "right", "Right", account_type)) %>%
group_by(account_type, word) %>% tally() %>%
filter(n > 100) %>%
left_join(tidy_politics %>%
mutate(account_type = ifelse(account_type == "right", "Right", account_type)) %>%
count(account_type, sort = TRUE) %>% rename(total = n)) %>%
mutate(proportion = n/total)
library(scales)
for_graph %>% ungroup() %>%
select(-n, -total) %>%
spread(account_type, proportion) %>%
ggplot(aes(left, Right)) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
geom_abline(color = "red")
View(tidy_politics)
head(tidy_politics)
tidy_politics <- politics %>% select(content, publish_date, account_type) %>%
mutate(content = tm::removeNumbers(str_replace_all(content, replace_reg, ""))) %>%
mutate(content = gsub("[^[:alnum:][:space:]]","",mutate))
unnest_tokens(word, content, token = "regex", pattern = unnest_reg) %>%
anti_join(stop_words) %>% anti_join(my_words)
tidy_politics <- politics %>% select(content, publish_date, account_type) %>%
mutate(content = tm::removeNumbers(str_replace_all(content, replace_reg, ""))) %>%
mutate(content = gsub("[^[:alnum:][:space:]]","",content)) %>%
unnest_tokens(word, content, token = "regex", pattern = unnest_reg) %>%
anti_join(stop_words) %>% anti_join(my_words)
for_graph <- tidy_politics %>% mutate(account_type = ifelse(account_type == "right", "Right", account_type)) %>%
group_by(account_type, word) %>% tally() %>%
filter(n > 100) %>%
left_join(tidy_politics %>%
mutate(account_type = ifelse(account_type == "right", "Right", account_type)) %>%
count(account_type, sort = TRUE) %>% rename(total = n)) %>%
mutate(proportion = n/total)
library(scales)
for_graph %>% ungroup() %>%
select(-n, -total) %>%
spread(account_type, proportion) %>%
ggplot(aes(left, Right)) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
geom_abline(color = "red")
head(tidy_politics)
